{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b7b93835-d14e-4dbc-8d39-97b4263c707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/ksa/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "405b01e3-233d-422c-a8f1-5856c18c54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "\n",
    "from esa_snappy import ProductIO\n",
    "from esa_snappy import GeoPos\n",
    "from esa_snappy import PixelPos\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='pandas', lineno=11)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1950a653-c3d7-4488-af38-b212a4c44d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'not imputed'\n",
    "idprov = '63'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5ea3fe5f-78e8-4890-96e1-92d378821e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VH_30', 'VH_29', 'VH_28', 'VH_27', 'VH_26', 'VH_25', 'VH_24', 'VH_23', 'VH_22', 'VH_21', 'VH_20', 'VH_19', 'VH_18', 'VH_17', 'VH_16', 'VH_15', 'VH_14', 'VH_13', 'VH_12', 'VH_11', 'VH_10', 'VH_9', 'VH_8', 'VH_7', 'VH_6', 'VH_5', 'VH_4', 'VH_3', 'VH_2', 'VH_1', 'VH_0']\n"
     ]
    }
   ],
   "source": [
    "## Get ID and Year \n",
    "years = range(2021, 2024)\n",
    "numbers = range(1, 31)\n",
    "year_id_ = []\n",
    "for year in years:\n",
    "    for number in numbers:\n",
    "        year_id_.append(f\"{year}_{str(number).zfill(2)}\")\n",
    "year_id_[:5]\n",
    "\n",
    "vh_list = [f\"VH_{i}\" for i in range(30, -1, -1)]\n",
    "print(vh_list)\n",
    "\n",
    "# vv_list = [f\"VV_{i}\" for i in range(30, -1, -1)]\n",
    "# print(vv_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8b93f37d-0c6c-4851-8274-bb5e41ed983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prep DF\n",
    "df_all_wide = pd.DataFrame(columns=[\"idpoint\"]+year_id_)\n",
    "# df_all_wide\n",
    "\n",
    "df_bridging_citra = pd.read_excel(\"/data/ksa/03_Sampling/bridging.xlsx\", dtype='object', sheet_name=\"periode_to_date\")\n",
    "# df_bridging_citra.head(2)\n",
    "\n",
    "df_bridging_ksa = pd.read_excel(\"/data/ksa/03_Sampling/bridging.xlsx\", dtype='object')\n",
    "# df_bridging_ksa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a6b74b42-198e-4124-8667-51205f921dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_values(data, idprov, mgrs):\n",
    "    if(data == 'not imputed'):\n",
    "        with open('/data/ksa/03_Sampling/data/'+idprov+'/sampling_'+mgrs+'.pkl', 'rb') as f:\n",
    "            df_values = pickle.load(f)    \n",
    "        df_values[\"VH\"] = df_values.Sigma0_VH_db\n",
    "        # df_values[\"VV\"] = df_values.Sigma0_VV_db\n",
    "        # df_values.drop([\"Sigma0_VH_db\",\"Sigma0_VV_db\"],axis=True, inplace=True)\n",
    "        df_values.drop([\"Sigma0_VH_db\"],axis=True, inplace=True)\n",
    "    elif(data == 'imputed'):\n",
    "        with open('/data/ksa/04_Data_Preprocessing/'+idprov+'/01_imputation/'+mgrs+'_imputed_data.pkl', 'rb') as f:\n",
    "            df_values = pickle.load(f) \n",
    "        # print(df_values.columns)\n",
    "        df_values[\"VH\"] = df_values.Sigma0_VH_db_imputation\n",
    "        # df_values[\"VV\"] = df_values.Sigma0_VV_db_imputation\n",
    "        # df_values.drop([\"Sigma0_VH_db_imputation\",\"Sigma0_VV_db_imputation\"],axis=True, inplace=True)\n",
    "        df_values.drop([\"Sigma0_VH_db_imputation\"],axis=True, inplace=True)\n",
    "    return df_values\n",
    "\n",
    "def reformat_to_wide(df_values, band, df_bridging_citra, df_all_wide):\n",
    "    \n",
    "    df_values[\"periode_start\"] = df_values.periode.str[4:8]\n",
    "    df_values[\"periode_end\"] = df_values.periode.str[-4:]\n",
    "    df_values[\"is_kabisat\"] = 0\n",
    "    \n",
    "    df_values = df_values.merge(df_bridging_citra, left_on=['periode_start','periode_end','is_kabisat'],  right_on=['periode_start','periode_end','is_kabisat'])\n",
    "    df_values['year_id_per_image'] = df_values.periode.str[:4]+\"_\"+df_values.id_per_image.astype(\"str\").str.zfill(2)\n",
    "    \n",
    "    df_VH_wide_res = df_values.sort_values('year_id_per_image').pivot(index='idpoint', columns='year_id_per_image', values=band).reset_index()\n",
    "    df_VH_wide_res = pd.concat([df_all_wide, df_VH_wide_res], axis=0)\n",
    "    df_VH_wide_res['idsubsegmen'] = df_VH_wide_res.idpoint.str[:-3]\n",
    "    return df_VH_wide_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ec02dd68-e780-488f-ab31-b71804cc6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_label = pd.read_csv(\"/data/raw/processed/relabelled_data_ksa.csv\")\n",
    "\n",
    "# df_label = df_label.merge(df_bridging_ksa.query(\"is_kabisat == 0\"), how='left', left_on='bulan', right_on='obs_in_a_year')\n",
    "# df_label['year_id_per_image'] = \"20\"+df_label.tahun.astype(\"str\")+\"_\"+df_label.id_per_image.astype(\"str\").str.zfill(2)\n",
    "# df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5473e763-970c-4188-ae65-839f1399bc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4322808, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tahun</th>\n",
       "      <th>bulan</th>\n",
       "      <th>idsubsegmen_repair</th>\n",
       "      <th>idsubsegmen_old</th>\n",
       "      <th>nth</th>\n",
       "      <th>id_x</th>\n",
       "      <th>observation</th>\n",
       "      <th>class</th>\n",
       "      <th>is_kabisat</th>\n",
       "      <th>obs_in_a_year</th>\n",
       "      <th>id_per_image</th>\n",
       "      <th>periode_start</th>\n",
       "      <th>periode_end</th>\n",
       "      <th>year_id_per_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>110101001A1</td>\n",
       "      <td>110101001A1</td>\n",
       "      <td>0</td>\n",
       "      <td>110101001A1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0125</td>\n",
       "      <td>0205</td>\n",
       "      <td>2022_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>110101001A2</td>\n",
       "      <td>110101001B1</td>\n",
       "      <td>0</td>\n",
       "      <td>110101001A2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0125</td>\n",
       "      <td>0205</td>\n",
       "      <td>2022_03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tahun bulan idsubsegmen_repair idsubsegmen_old  nth         id_x  \\\n",
       "0     22     1        110101001A1     110101001A1    0  110101001A1   \n",
       "1     22     1        110101001A2     110101001B1    0  110101001A2   \n",
       "\n",
       "   observation class is_kabisat obs_in_a_year id_per_image periode_start  \\\n",
       "0          8.0    NV          0             1            3          0125   \n",
       "1          4.0     H          0             1            3          0125   \n",
       "\n",
       "  periode_end year_id_per_image  \n",
       "0        0205           2022_03  \n",
       "1        0205           2022_03  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repair = pd.read_csv(\"/data/raw/processed/data_ksa_long_relabeled_repair.csv\")\n",
    "df_repair = df_repair[[\"tahun\",\"bulan\",'idsubsegmen_repair', 'idsubsegmen_old', 'nth', 'id_x', 'observation',\n",
    "       'class']].merge(df_bridging_ksa.query(\"is_kabisat == 0\"), how='left', left_on='bulan', right_on='obs_in_a_year')\n",
    "df_repair['year_id_per_image'] = \"20\"+df_repair.tahun.astype(\"str\")+\"_\"+df_repair.id_per_image.astype(\"str\").str.zfill(2)\n",
    "print(df_repair.shape)\n",
    "df_repair.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "67dfcb28-bedf-4152-81fe-17d80744ea2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2022_03', '2022_05', '2022_08', '2022_10', '2022_13', '2022_15',\n",
       "       '2022_18', '2022_20', '2022_23', '2022_25', '2022_28', '2022_30',\n",
       "       '2023_03', '2023_05', '2023_08', '2023_10', '2023_13', '2023_15',\n",
       "       '2023_18', '2023_20', '2023_23', '2023_25', '2023_28', '2023_30'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_id_per_image_ = df_label.year_id_per_image.unique()\n",
    "year_id_per_image_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c4feb594-1eb8-4d8d-b321-7b7d55551f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full.loc[df_full.idsubsegmen_old == '351217018C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1861b37e-e436-44eb-98c8-8a216c490ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpoint</th>\n",
       "      <th>idsubsegmen</th>\n",
       "      <th>idsubsegmen_repair</th>\n",
       "      <th>idsubsegmen_old</th>\n",
       "      <th>tahun</th>\n",
       "      <th>bulan</th>\n",
       "      <th>observation</th>\n",
       "      <th>class</th>\n",
       "      <th>year_id_per_image</th>\n",
       "      <th>kdpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320201009A1#01</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2022_03</td>\n",
       "      <td>#01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320201009A1#01</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2022_05</td>\n",
       "      <td>#01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320201009A1#01</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2022_08</td>\n",
       "      <td>#01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320201009A1#01</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2022_10</td>\n",
       "      <td>#01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320201009A1#01</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>320201009A1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2022_13</td>\n",
       "      <td>#01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idpoint  idsubsegmen idsubsegmen_repair idsubsegmen_old  tahun  \\\n",
       "0  320201009A1#01  320201009A1        320201009A1     320201009A1   22.0   \n",
       "1  320201009A1#01  320201009A1        320201009A1     320201009A1   22.0   \n",
       "2  320201009A1#01  320201009A1        320201009A1     320201009A1   22.0   \n",
       "3  320201009A1#01  320201009A1        320201009A1     320201009A1   22.0   \n",
       "4  320201009A1#01  320201009A1        320201009A1     320201009A1   22.0   \n",
       "\n",
       "  bulan  observation class year_id_per_image kdpoint  \n",
       "0     1          8.0    NV           2022_03     #01  \n",
       "1     2          8.0    NV           2022_05     #01  \n",
       "2     3          8.0    NV           2022_08     #01  \n",
       "3     4          8.0    NV           2022_10     #01  \n",
       "4     5          8.0    NV           2022_13     #01  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = df_VH_wide[['idpoint','idsubsegmen']].copy()\n",
    "df_full = df_full.merge(df_repair[['idsubsegmen_repair','idsubsegmen_old','tahun', 'bulan', 'observation', 'class', 'year_id_per_image']], how=\"left\", left_on = \"idsubsegmen\", right_on=\"idsubsegmen_old\")\n",
    "df_full['kdpoint'] = df_full['idpoint'].str[-3:]\n",
    "df_full['idpoint'] = df_full['idsubsegmen_repair'] +  df_full['kdpoint']\n",
    "df_full['idsubsegmen'] = df_full['idsubsegmen_repair']\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0cda5d4f-c8a6-41c7-86ae-9b10a4537734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50MMA',\n",
       " '50MLB',\n",
       " '50MLC',\n",
       " '50MLA',\n",
       " '50MMB',\n",
       " '50MKA',\n",
       " '50MKC',\n",
       " '50MKB',\n",
       " '50MMC']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cek error mgrs\n",
    "mgrs_done_ = os.listdir('/data/ksa/03_Sampling/data/'+idprov+'/') \n",
    "mgrs_done_ = [x for x in mgrs_done_ if \".pkl\" in x]\n",
    "mgrs_done_ = [x[-9:-4] for x in mgrs_done_]\n",
    "mgrs_done_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e08c1987-ed2f-43e5-8b2c-d831fc8cbc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:40<00:00, 24.51s/it]\n"
     ]
    }
   ],
   "source": [
    "for mgrs in tqdm(mgrs_done_):\n",
    "    df_values = get_df_values(data, idprov, mgrs)\n",
    "    df_VH_wide = reformat_to_wide(df_values, \"VH\", df_bridging_citra, df_all_wide)\n",
    "\n",
    "    # df_full = df_VH_wide[['idpoint','idsubsegmen']].copy()\n",
    "    # df_full = df_full.merge(df_label[['id_x','tahun', 'bulan', 'obs', 'class', 'year_id_per_image']], how=\"left\", left_on = \"idsubsegmen\", right_on=\"id_x\")\n",
    "    \n",
    "    df_full = df_VH_wide[['idpoint','idsubsegmen']].copy()\n",
    "    df_full = df_full.merge(df_repair[['idsubsegmen_repair','idsubsegmen_old','tahun', 'bulan', 'observation', 'class', 'year_id_per_image']], how=\"left\", left_on = \"idsubsegmen\", right_on=\"idsubsegmen_old\")\n",
    "    df_full['kdpoint'] = df_full['idpoint'].str[-3:]\n",
    "    df_full['idpoint'] = df_full['idsubsegmen_repair'] +  df_full['kdpoint']\n",
    "    df_full['idsubsegmen'] = df_full['idsubsegmen_repair']\n",
    "\n",
    "    df_wide_full = pd.DataFrame()\n",
    "    for yi in year_id_per_image_:\n",
    "        df_tmp = df_full.loc[df_full.year_id_per_image == yi]\n",
    "        df_tmp.loc[:,'MGRS'] = mgrs\n",
    "        ind = df_VH_wide.columns.to_list().index(yi)+1\n",
    "        df_wide_tmp = pd.concat([df_VH_wide.iloc[:,0:1], df_VH_wide.iloc[:,ind-31:ind]], axis=1)\n",
    "        df_wide_res = df_tmp.merge(df_wide_tmp, how='left', left_on='idpoint', right_on='idpoint')\n",
    "        df_wide_res.columns.values[-31:] = vh_list\n",
    "        df_wide_full = pd.concat([df_wide_full,df_wide_res], axis=0) \n",
    "        # break\n",
    "    # break\n",
    "    if(data == 'not imputed'):\n",
    "        with open('/data/ksa/03_Sampling/data-wide/'+idprov+'/wide_data_'+mgrs+'.pkl', 'wb') as f:\n",
    "            pickle.dump(df_wide_full, f)\n",
    "    elif(data == 'imputed'):\n",
    "        with open('/data/ksa/04_Data_Preprocessing/'+idprov+'/01_imputation/wide_data/wide_data_'+mgrs+'.pkl', 'wb') as f:\n",
    "            pickle.dump(df_wide_full, f)\n",
    "    df_wide_full\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca598d42-6513-45f8-9cad-1d18ad0e0e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpoint</th>\n",
       "      <th>idsubsegmen</th>\n",
       "      <th>idsubsegmen_repair</th>\n",
       "      <th>idsubsegmen_old</th>\n",
       "      <th>tahun</th>\n",
       "      <th>bulan</th>\n",
       "      <th>observation</th>\n",
       "      <th>class</th>\n",
       "      <th>year_id_per_image</th>\n",
       "      <th>kdpoint</th>\n",
       "      <th>...</th>\n",
       "      <th>VH_9</th>\n",
       "      <th>VH_8</th>\n",
       "      <th>VH_7</th>\n",
       "      <th>VH_6</th>\n",
       "      <th>VH_5</th>\n",
       "      <th>VH_4</th>\n",
       "      <th>VH_3</th>\n",
       "      <th>VH_2</th>\n",
       "      <th>VH_1</th>\n",
       "      <th>VH_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630215002A1#01</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2022_03</td>\n",
       "      <td>#01</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.458991</td>\n",
       "      <td>-14.534101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.453424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.742740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.295194</td>\n",
       "      <td>-14.961252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630215002A1#02</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2022_03</td>\n",
       "      <td>#02</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.793771</td>\n",
       "      <td>-13.768745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.049233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.841273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.602156</td>\n",
       "      <td>-11.690808</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630215002A1#03</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2022_03</td>\n",
       "      <td>#03</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.865894</td>\n",
       "      <td>-14.213884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.924355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.085409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.336298</td>\n",
       "      <td>-12.325940</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630215002A1#04</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2022_03</td>\n",
       "      <td>#04</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.957108</td>\n",
       "      <td>-13.740613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.464873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.626237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.597968</td>\n",
       "      <td>-12.688139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630215002A1#05</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>630215002A1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2022_03</td>\n",
       "      <td>#05</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.086611</td>\n",
       "      <td>-11.971251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.862750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.216900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.512072</td>\n",
       "      <td>-12.915163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>630220005C3#21</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2023_30</td>\n",
       "      <td>#21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.113348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.291942</td>\n",
       "      <td>-12.226669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.461864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.981815</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>630220005C3#22</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2023_30</td>\n",
       "      <td>#22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.421253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.396297</td>\n",
       "      <td>-13.152828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.117857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.648221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>630220005C3#23</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2023_30</td>\n",
       "      <td>#23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.522540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.259372</td>\n",
       "      <td>-13.016039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.004348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.216055</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>630220005C3#24</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2023_30</td>\n",
       "      <td>#24</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.791525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.161838</td>\n",
       "      <td>-13.963500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.232998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.208263</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>630220005C3#25</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>630220005C3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NP</td>\n",
       "      <td>2023_30</td>\n",
       "      <td>#25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.617393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.311502</td>\n",
       "      <td>-16.198359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.247041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.111042</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21600 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            idpoint  idsubsegmen idsubsegmen_repair idsubsegmen_old  tahun  \\\n",
       "0    630215002A1#01  630215002A1        630215002A1     630215002A1     22   \n",
       "1    630215002A1#02  630215002A1        630215002A1     630215002A1     22   \n",
       "2    630215002A1#03  630215002A1        630215002A1     630215002A1     22   \n",
       "3    630215002A1#04  630215002A1        630215002A1     630215002A1     22   \n",
       "4    630215002A1#05  630215002A1        630215002A1     630215002A1     22   \n",
       "..              ...          ...                ...             ...    ...   \n",
       "895  630220005C3#21  630220005C3        630220005C3     630220005C3     23   \n",
       "896  630220005C3#22  630220005C3        630220005C3     630220005C3     23   \n",
       "897  630220005C3#23  630220005C3        630220005C3     630220005C3     23   \n",
       "898  630220005C3#24  630220005C3        630220005C3     630220005C3     23   \n",
       "899  630220005C3#25  630220005C3        630220005C3     630220005C3     23   \n",
       "\n",
       "    bulan  observation class year_id_per_image kdpoint  ...       VH_9  \\\n",
       "0       1          7.0    NP           2022_03     #01  ... -13.458991   \n",
       "1       1          7.0    NP           2022_03     #02  ... -15.793771   \n",
       "2       1          7.0    NP           2022_03     #03  ... -13.865894   \n",
       "3       1          7.0    NP           2022_03     #04  ... -12.957108   \n",
       "4       1          7.0    NP           2022_03     #05  ... -13.086611   \n",
       "..    ...          ...   ...               ...     ...  ...        ...   \n",
       "895    12          7.0    NP           2023_30     #21  ...        NaN   \n",
       "896    12          7.0    NP           2023_30     #22  ...        NaN   \n",
       "897    12          7.0    NP           2023_30     #23  ...        NaN   \n",
       "898    12          7.0    NP           2023_30     #24  ...        NaN   \n",
       "899    12          7.0    NP           2023_30     #25  ...        NaN   \n",
       "\n",
       "          VH_8  VH_7       VH_6       VH_5       VH_4       VH_3       VH_2  \\\n",
       "0   -14.534101   NaN -11.453424        NaN -12.742740        NaN -13.295194   \n",
       "1   -13.768745   NaN -14.049233        NaN -12.841273        NaN -11.602156   \n",
       "2   -14.213884   NaN -13.924355        NaN -13.085409        NaN -10.336298   \n",
       "3   -13.740613   NaN -13.464873        NaN -11.626237        NaN -11.597968   \n",
       "4   -11.971251   NaN -12.862750        NaN -12.216900        NaN -12.512072   \n",
       "..         ...   ...        ...        ...        ...        ...        ...   \n",
       "895 -12.113348   NaN -14.291942 -12.226669        NaN -13.461864        NaN   \n",
       "896 -12.421253   NaN -15.396297 -13.152828        NaN -16.117857        NaN   \n",
       "897 -12.522540   NaN -12.259372 -13.016039        NaN -15.004348        NaN   \n",
       "898 -12.791525   NaN -14.161838 -13.963500        NaN -15.232998        NaN   \n",
       "899 -13.617393   NaN -14.311502 -16.198359        NaN -14.247041        NaN   \n",
       "\n",
       "          VH_1  VH_0  \n",
       "0   -14.961252   NaN  \n",
       "1   -11.690808   NaN  \n",
       "2   -12.325940   NaN  \n",
       "3   -12.688139   NaN  \n",
       "4   -12.915163   NaN  \n",
       "..         ...   ...  \n",
       "895 -12.981815   NaN  \n",
       "896 -13.648221   NaN  \n",
       "897 -14.216055   NaN  \n",
       "898 -14.208263   NaN  \n",
       "899 -14.111042   NaN  \n",
       "\n",
       "[21600 rows x 42 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78ef58-9380-4a8b-8bd1-8de5f06145c8",
   "metadata": {},
   "source": [
    "## samplign_VH / sampling_VV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "32c8e1e6-bca2-45da-a865-aa133464e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode_dict = {\n",
    "#     'V1': '1.0',\n",
    "#     'V2': '2.0',\n",
    "#     'G': '3.0',\n",
    "#     'H': '4.0',\n",
    "#     'PL': '5.0',\n",
    "#     'P': '99.0',\n",
    "#     'NP': '6.0',\n",
    "#     'NV': '7.0',\n",
    "#     'BL': '0.0'\n",
    "# }\n",
    "\n",
    "# mgrs_ = ['48MXT', '48MYT', '48MXU', '48MXS', '48MYS', '48MZT', '48MZS',\n",
    "#        '49MAN', '49MAM', '49MBM', '49MBN', '49MAP', '49MBP', '48MZU',\n",
    "#        '48MYU']\n",
    "# mgrs\n",
    "\n",
    "recode_dict = {\n",
    "    'V1':1,\n",
    "    'V2':2,\n",
    "    'G':3,\n",
    "    'H':4,\n",
    "    'BP':0,\n",
    "    'PL':5,\n",
    "    'BPL':0,\n",
    "    'NP':6,\n",
    "    'NV':6,\n",
    "    None:99\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fcf93871-6f66-49eb-b43e-b20c3d03a73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NV', 'V2', 'G', 'V1', 'BPL', 'NP', 'H', 'PL', 'BP'], dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampling['class'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "eceae334-d22c-459e-a54a-d95b353d63b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:21<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "for mgrs in tqdm(mgrs_done_):\n",
    "    if(data == 'not imputed'):\n",
    "        with open('/data/ksa/03_Sampling/data-wide/'+idprov+'/wide_data_'+mgrs+'.pkl', 'rb') as f:\n",
    "            df_sampling = pickle.load(f)\n",
    "    elif(data == 'imputed'):\n",
    "        with open('/data/ksa/04_Data_Preprocessing/'+idprov+'/01_imputation/wide_data/wide_data_'+mgrs+'.pkl', 'rb') as f:\n",
    "            df_sampling = pickle.load(f)\n",
    "\n",
    "    df_sampling['observation'] = df_sampling['class'].replace(recode_dict)\n",
    "    df_sampling = df_sampling.loc[df_sampling.observation != 'P']\n",
    "    # df_sampling = df_sampling.loc[df_sampling.observation != '99.0']\n",
    "    df_sampling = df_sampling.loc[df_sampling.observation != 99]\n",
    "    df_sampling['idsegment'] = df_sampling['idsubsegmen'].str[:-2]\n",
    "    df_sampling.rename(columns={'idsubsegmen': 'idsubsegment'}, inplace=True)\n",
    "    df_sampling.rename(columns={'bulan': 'nth'}, inplace=True)\n",
    "    df_sampling.rename(columns={'year_id_per_image': 'periode'}, inplace=True)\n",
    "    \n",
    "    df_sampling = df_sampling[['idpoint','idsubsegment','idsegment','nth','periode',\n",
    "     'observation','class', 'MGRS', 'VH_30', 'VH_29', 'VH_28', 'VH_27', 'VH_26', 'VH_25',\n",
    "     'VH_24', 'VH_23', 'VH_22', 'VH_21', 'VH_20', 'VH_19', 'VH_18', 'VH_17',\n",
    "     'VH_16', 'VH_15', 'VH_14', 'VH_13', 'VH_12', 'VH_11', 'VH_10', 'VH_9',\n",
    "     'VH_8', 'VH_7', 'VH_6', 'VH_5', 'VH_4', 'VH_3', 'VH_2', 'VH_1', 'VH_0']]\n",
    "\n",
    "    # df_sampling = df_sampling[['idpoint','idsubsegment','idsegment','nth','periode',\n",
    "    #  'observation', 'class','MGRS', 'VV_30', 'VV_29', 'VV_28', 'VV_27', 'VV_26', 'VV_25',\n",
    "    #  'VV_24', 'VV_23', 'VV_22', 'VV_21', 'VV_20', 'VV_19', 'VV_18', 'VV_17',\n",
    "    #  'VV_16', 'VV_15', 'VV_14', 'VV_13', 'VV_12', 'VV_11', 'VV_10', 'VV_9',\n",
    "    #  'VV_8', 'VV_7', 'VV_6', 'VV_5', 'VV_4', 'VV_3', 'VV_2', 'VV_1', 'VV_0']]\n",
    "    \n",
    "    if(data == 'not imputed'):\n",
    "        with open('/data/ksa/03_Sampling/data-wide/'+idprov+'/sampling_VH_'+mgrs+'.pkl', 'wb') as f:\n",
    "                pickle.dump(df_sampling, f)\n",
    "    elif(data == 'imputed'):\n",
    "        with open('/data/ksa/04_Data_Preprocessing/'+idprov+'/wide_data/sampling_VH_'+mgrs+'.pkl', 'wb') as f:\n",
    "            pickle.dump(df_sampling, f)\n",
    "\n",
    "    # if(data == 'not imputed'):\n",
    "    #     with open('/data/ksa/03_Sampling/data-wide/32/sampling_VV_'+mgrs+'.pkl', 'wb') as f:\n",
    "    #             pickle.dump(df_sampling, f)\n",
    "    # elif(data == 'imputed'):\n",
    "    #     with open('/data/ksa/04_Data_Preprocessing/32/01_imputation/wide_data/sampling_VV_'+mgrs+'.pkl', 'wb') as f:\n",
    "    #         pickle.dump(df_sampling, f)\n",
    "            \n",
    "    \n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "acd2c520-db24-4ce4-83ce-d96be6dbf4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 2, 1, 0, 3, 5], dtype=object)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampling.observation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2b318194-9a82-4add-898c-f7026e1c4acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "observation  class\n",
       "0            BP       4750\n",
       "             BPL      1100\n",
       "1            V1        450\n",
       "2            V2        375\n",
       "3            G         375\n",
       "4            H         500\n",
       "5            PL        600\n",
       "6            NP       7700\n",
       "             NV       3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampling.groupby(['observation','class']).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
