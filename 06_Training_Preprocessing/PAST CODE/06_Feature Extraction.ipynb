{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb80c1fd-256d-416e-94ca-eeda098700a0",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d50645-136a-41ca-8503-8a5dcd92b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5580c-01cd-4a8a-a14e-86f69f346fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../shared_pemetaan/2023/Mixed Method/[2024] Preprocessed Dataset/[03] df_all.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183af9a-a4ec-49a7-8748-34688bed7b1c",
   "metadata": {},
   "source": [
    "## Feature Extraction for Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad1bfa-581f-4b73-a287-743dad4abb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract 17 Features\n",
    "## Features are constructed to represent the phenological growth phases of paddy \n",
    "## Derived from either one growth cycle and one year, as described in the following table\n",
    "\n",
    "\n",
    "def extract_features(data):\n",
    "    \n",
    "    ## Fitur Fase Tumbuh\n",
    "\n",
    "    # backscatter at t0 \n",
    "    data[f'F1'] = data[f'VH_0']\n",
    "    # min backscatter in the last 10 time points (one growth cycle)\n",
    "    data[f'F2'] = data.loc[:, f'VH_0':f'VH_9'].min(axis=1)\n",
    "    # max backscatter in the last 10 time points (one growth cycle)\n",
    "    data[f'F3'] = data.loc[:, f'VH_0':f'VH_9'].max(axis=1)\n",
    "    # time range from t-0 to Min backscatter in the last 10 time points (one growth cycle)\n",
    "    data[f'F4'] = data.loc[:, f'VH_0':f'VH_9'].idxmin(axis=1)\n",
    "    data[f'F4'] = data[f'F4'].str.extract(r'VH_(\\d+)')[0].astype(int)\n",
    "    # time range from t0 to Max backscatter in the last 10 time points (one growth cycle)\n",
    "    data[f'F5'] = data.loc[:, f'VH_0':f'VH_9'].idxmax(axis=1)\n",
    "    data[f'F5'] = data[f'F5'].str.extract(r'VH_(\\d+)')[0].astype(int)\n",
    "\n",
    "    ## Fitur Tahunan\n",
    "    \n",
    "    # min backscatter in the last year\n",
    "    data[f'F6'] = data.loc[:, f'VH_0':f'VH_31'].min(axis=1)\n",
    "    # max backscatter in the last year\n",
    "    data[f'F7'] = data.loc[:, f'VH_0':f'VH_31'].max(axis=1)\n",
    "    # deviation/Variance\n",
    "    data[f'F8'] = data[f'F7'] - data[f'F6']\n",
    "    \n",
    "    # total harvesting events in one year*\n",
    "    def get_n(gelombang):\n",
    "        jumlah_gelombang = 0\n",
    "        for i in range(1, (len(gelombang) - 1)):\n",
    "            if (gelombang[i - 1] < gelombang[i]) and (gelombang[i] > gelombang[i + 1]):  # Puncak\n",
    "                jumlah_gelombang += 1\n",
    "            elif (gelombang[i - 1] > gelombang[i]) and (gelombang[i] < gelombang[i + 1]):  # Lembah\n",
    "                jumlah_gelombang += 1 \n",
    "        return math.floor(jumlah_gelombang/2)\n",
    "\n",
    "    def getF9(df):\n",
    "        n_ = df.loc[:, f'VH_0':f'VH_31'].apply(get_n, axis=1)\n",
    "        return n_\n",
    "\n",
    "    data[f'F9'] = getF9(data)\n",
    "    \n",
    "    \n",
    "    ## Slope \n",
    "    \n",
    "    # slope between t_0 and t_1\n",
    "    data[f'F10']=data.apply(lambda y: (y[f'VH_0']-y[f'VH_1']+1e-10),axis=1)\n",
    "    # degree of slope between t_0 and t_1\n",
    "    data[f'F11']=data.apply(lambda y: math.atan(y[f'F10']),axis=1)\n",
    "    # slope between highest data\n",
    "    data[f'F12']=data.apply(lambda y: (y[f'VH_0']-y[f'F2']+1e-10)/(y[f'F4']+1e-10),axis=1)\n",
    "    # degree of slope between highest data\n",
    "    data[f'F13']=data.apply(lambda y: math.atan(y[f'F12']),axis=1)\n",
    "    # slope between lowest data\n",
    "    data[f'F14']=data.apply(lambda y: (y[f'VH_0']-y[f'F3']+1e-10)/(y[f'F5']+1e-10),axis=1)\n",
    "    # degree of slope between lowest data\n",
    "    data[f'F15']=data.apply(lambda y: math.atan(y[f'F14']),axis=1)\n",
    "    # slope between  t_0 and t_10\n",
    "    data[f'F16']=data.apply(lambda y: (y[f'VH_0']-y[f'VH_10']+1e-10),axis=1)\n",
    "    # degree of slope between t_0 and t_10\n",
    "    data[f'F17']=data.apply(lambda y: math.atan(y[f'F16']),axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c253a42-ee91-4bd4-a8df-01a7002b72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted = extract_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0b9e1-4d08-4714-a7bc-99725093292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted = df_extracted[['idsegment','id_subsegment', 'nth', 'periode',\n",
    "       'observation','VH_0', 'VH_1', 'VH_2', 'VH_3', 'VH_4', 'VH_5', 'VH_6',\n",
    "       'VH_7', 'VH_8', 'VH_9', 'VH_10', 'VH_11', 'VH_12', 'VH_13', 'VH_14',\n",
    "       'VH_15', 'VH_16', 'VH_17', 'VH_18', 'VH_19', 'VH_20', 'VH_21', 'VH_22',\n",
    "       'VH_23', 'VH_24', 'VH_25', 'VH_26', 'VH_27', 'VH_28', 'VH_29', 'VH_30',\n",
    "       'VH_31','F1', 'F2', 'F3', 'F4', 'F5', 'F6',\n",
    "       'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16',\n",
    "       'F17']]\n",
    "df_extracted = df_extracted.sort_values(by=['idsegment','id_subsegment'])\n",
    "df_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9716d-3f92-4dac-886a-8b32e28f8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "variabel_list = [f'F{i}' for i in range(1,18)]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, var in enumerate(variabel_list):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x='obs', y=var, data=df_extracted)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd9845-369f-44de-807d-c3dcea8f244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_extracted.to_csv('sampel_to_explore.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd410a-6372-4c7d-be81-ac71ebf4ade7",
   "metadata": {},
   "source": [
    "## Calculate DTW Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df935ca-d46e-492a-ba5c-58300e2e692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keterangan : https://chatgpt.com/share/68481f45-bb91-4228-b45a-179a52d9954b\n",
    "## Get median of each observation, each label in a year\n",
    "\n",
    "def prepare_median(X,id_vars,value_vars,group_var):\n",
    "    data_melt=pd.melt(X,id_vars=id_vars,value_vars=value_vars)\n",
    "    data_melt[group_var]=data_melt[group_var].astype(str)\n",
    "    grouped=pd.pivot_table(data=data_melt,index='variable',values='value',columns=group_var,\n",
    "                           aggfunc=[np.median]).reset_index()\n",
    "    grouped.columns = grouped.columns.map('_'.join).str.strip('_')\n",
    "    grouped['variable_dt']=grouped.variable.apply(lambda y:int(y.split('_')[1]))\n",
    "    grouped=grouped.sort_values('variable_dt',ascending=False)\n",
    "    col_group_2=['variable_dt']+[i for i in grouped.columns if i[0]=='m']\n",
    "    grouped_melt_median=pd.melt(\n",
    "        grouped[col_group_2],\n",
    "        id_vars='variable_dt',\n",
    "        value_vars=[i for i in grouped.columns if i[0]=='m'])\n",
    "    return grouped_melt_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71de96e-fccc-43e4-b685-3f704255a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate dtw of observtion and the median, up to up_limit, for each class\n",
    "## Add [num of paddy growth phase class] more class \n",
    "\n",
    "def calculate_dtw(X,median,up_limit,suffix,s_var):\n",
    "    median=median.query('variable_dt<=@up_limit').sort_values('variable_dt',ascending=True)\n",
    "    col_=[f't_{i}_{suffix}' for i in np.arange(0,up_limit)]\n",
    "    for i in tqdm(np.arange(0,len(median.variable.unique()))):\n",
    "        med_check=median.loc[median['variable']=='median_'+str(i)].value.to_numpy()\n",
    "        #break\n",
    "        #print(med_check)\n",
    "        X[f'dtw_{i}_{s_var}']=X[col_].apply(lambda y: dtw.distance(y,med_check),axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f7c24-1fd1-4ca7-b590-2ef6f6f609e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y,stratify=Y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_temp, Y_temp, stratify=Y_temp,test_size=0.5, random_state=42)\n",
    "X_copy=X_train.copy().assign(target=Y_train).assign(keys=lambda y:y.index)\n",
    "\n",
    "median_10m=prepare_median(X_copy,id_vars=['keys','target'],value_vars=[f't_{31-i}_10m' for i in np.arange(0,32)],group_var='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7ad72-98a4-4bff-a37e-01ba21000f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=calculate_dtw(X_train,median_10m,32,'10m','31')\n",
    "X_train=calculate_dtw(X_train,median_10m,12,'10m','11')\n",
    "X_train=calculate_dtw(X_train,median_10m,8,'10m','7')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
