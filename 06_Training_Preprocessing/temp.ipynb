{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc86888-6a68-47f0-8e31-e424604c7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from whittaker_eilers import WhittakerSmoother\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6f2da3-cff9-4d43-a4bd-0e31c750d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_pairs(year):\n",
    "    start_date = datetime(year, 1, 1)\n",
    "    date_pairs = []\n",
    "    while start_date.year == year:\n",
    "        end_date = start_date + timedelta(days=11)\n",
    "        if end_date.year != year:\n",
    "            break\n",
    "        date_pairs.append([start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')])\n",
    "        start_date = end_date + timedelta(days=1)\n",
    "    return date_pairs\n",
    "\n",
    "def prepare_dates():\n",
    "    list_date = []\n",
    "    for year in [2021, 2022, 2023]:\n",
    "        list_date.extend(generate_date_pairs(year))\n",
    "    list_date = [f\"{start.replace('-', '')}_{end.replace('-', '')}\" for start, end in list_date]\n",
    "    return list_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d17a40-4855-46ba-9526-33c80fbea168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 15 data\n"
     ]
    }
   ],
   "source": [
    "kdprov='32'\n",
    "pickle_prov = glob(f'/data/ksa/03_Sampling/data/{kdprov}/*.pkl')\n",
    "print('Found:', len(pickle_prov), 'data')\n",
    "list_date = prepare_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0079e8a1-a115-4f8c-a503-04f689bc5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_preparation(ls_pickle):\n",
    "    with open(ls_pickle, 'rb') as file:\n",
    "        dt_pkl = pickle.load(file)\n",
    "    return dt_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb114fa1-854f-471b-b053-6e9534010fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_prov=['/data/ksa/03_Sampling/data/32/sampling_48MYU.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7aacf9-7d0a-4067-a5f5-7f47520a0558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 46710/49650 [3:22:50<2:58:58,  3.65s/it]IOStream.flush timed out\n",
      "100%|██████████| 49650/49650 [3:39:39<00:00,  3.77it/s]  \n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "d_pkl = None\n",
    "temp = pd.DataFrame()\n",
    "\n",
    "def process_idpoint(j, dt_pkl, list_date, mgrs_map):\n",
    "    u = dt_pkl.query('idpoint == @j').sort_values('periode')\n",
    "    ls_date = pd.DataFrame({'periode': list_date})\n",
    "    temp2 = pd.merge(ls_date, u, how='left').fillna(0)\n",
    "    temp2['idpoint'] = j\n",
    "    temp2['MGRS'] = mgrs_map\n",
    "    temp2['weight'] = temp2.Sigma0_VH_db.apply(lambda y: 0 if y == 0 else 1)\n",
    "    if (temp2.weight.sum()/temp2.shape[0])>0.6:\n",
    "        whittaker_smoother = WhittakerSmoother(lmbda=1, order=2, data_length=temp2.shape[0], weights=temp2['weight'])\n",
    "        temp2['Sigma0_VH_db_interp'] = whittaker_smoother.smooth(temp2['Sigma0_VH_db'])\n",
    "        temp2['Sigma0_VV_db_interp'] = whittaker_smoother.smooth(temp2['Sigma0_VV_db'])\n",
    "        temp2['Sigma0_VH_db_imputted'] = temp2.apply(lambda y: y['Sigma0_VH_db'] if y['Sigma0_VH_db'] != 0 else y['Sigma0_VH_db_interp'], axis=1)\n",
    "        temp2['Sigma0_VV_db_imputted'] = temp2.apply(lambda y: y['Sigma0_VV_db'] if y['Sigma0_VV_db'] != 0 else y['Sigma0_VV_db_interp'], axis=1)\n",
    "        return temp2\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "num_workers = 10  # Adjust this based on your system's capability\n",
    "\n",
    "for i in pickle_prov:\n",
    "    dt_pkl = do_preparation(i)\n",
    "    list_idpoint = dt_pkl.idpoint.unique()\n",
    "    mgrs_map = dt_pkl['MGRS'].unique()[0]\n",
    "\n",
    "    temp_list = [temp]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        print(num_workers)\n",
    "        results = list(tqdm(executor.map(process_idpoint, list_idpoint, [dt_pkl]*len(list_idpoint), [list_date]*len(list_idpoint), [mgrs_map]*len(list_idpoint)), total=len(list_idpoint)))\n",
    "\n",
    "    temp = pd.concat(temp_list + results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80c0c7e5-39ca-4087-a886-73c83331be8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             periode         idpoint   MGRS  Sigma0_VH_db  Sigma0_VV_db  \\\n",
      "0  20210101_20210112  321318003A1#01  48MYU    -16.498114     -6.830626   \n",
      "1  20210113_20210124  321318003A1#01  48MYU    -20.321995    -10.826198   \n",
      "2  20210125_20210205  321318003A1#01  48MYU      0.000000      0.000000   \n",
      "3  20210206_20210217  321318003A1#01  48MYU    -24.251793    -14.901100   \n",
      "4  20210218_20210301  321318003A1#01  48MYU      0.000000      0.000000   \n",
      "\n",
      "   weight  Sigma0_VH_db_interp  Sigma0_VV_db_interp  Sigma0_VH_db_imputted  \\\n",
      "0       1           -17.270226            -7.580071             -16.498114   \n",
      "1       1           -20.017186           -10.463774             -20.321995   \n",
      "2       0           -21.992033           -12.598032             -21.992033   \n",
      "3       1           -22.727463           -13.595825             -24.251793   \n",
      "4       0           -21.756172           -13.070132             -21.756172   \n",
      "\n",
      "   Sigma0_VV_db_imputted  \n",
      "0              -6.830626  \n",
      "1             -10.826198  \n",
      "2             -12.598032  \n",
      "3             -14.901100  \n",
      "4             -13.070132  \n"
     ]
    }
   ],
   "source": [
    "print(temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a18a44-27b3-4a74-8814-36b09b9da042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49638"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp.idpoint.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43cae195-6ebe-4cd9-ac48-678e81506917",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_missing_coverage.pkl','wb') as file:\n",
    "    pickle.dump(temp,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe21646-e266-4431-94e4-4b7267aa0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f445efe0-fec2-49e8-a799-ac2942c61fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpoint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idpoint\n",
       "weight         \n",
       "17            1\n",
       "18           17\n",
       "19        49632"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupby('weight').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d8c10-94c2-4754-a1e0-343ce5b613fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pkl=None\n",
    "temp = pd.DataFrame()\n",
    "for i in pickle_prov:\n",
    "    dt_pkl = do_preparation(i)\n",
    "    list_idpoint = dt_pkl.idpoint.unique()\n",
    "    mgrs_map = dt_pkl['MGRS'].unique()[0]\n",
    "    temp_list = [temp]\n",
    "    ls_date=pd.DataFrame({'periode':list_date})\n",
    "    for j in tqdm(list_idpoint):\n",
    "        u=dt_pkl.query('idpoint == @j').sort_values('periode')\n",
    "        temp2=pd.merge(ls_date,u,how='left').fillna(0)\n",
    "        temp2['idpoint']=j\n",
    "        temp2['MGRS']=mgrs_map\n",
    "        temp2['weight']=temp2.Sigma0_VH_db.apply(lambda y: 0 if y==0 else 1)\n",
    "        temp2 = temp2.iloc[-30:].groupby('idpoint', as_index=False).sum()[['idpoint', 'weight']]\n",
    "        temp_list.append(temp2)\n",
    "    temp = pd.concat(temp_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd8f83-3d0a-4b85-9265-c92ee5530772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "temp = []\n",
    "\n",
    "# Preconvert list_date to a DataFrame only once\n",
    "ls_date = pd.DataFrame({'periode': list_date})\n",
    "\n",
    "for i in pickle_prov:\n",
    "    dt_pkl = do_preparation(i)\n",
    "    list_idpoint = dt_pkl['idpoint'].unique()\n",
    "    mgrs_value = dt_pkl['MGRS'].unique()[0]  # Assuming this is consistent for all idpoints\n",
    "    \n",
    "    for j in tqdm(list_idpoint):\n",
    "        u = dt_pkl[dt_pkl['idpoint'] == j].sort_values('periode')\n",
    "        \n",
    "        # Directly create an empty DataFrame with the necessary columns and append data\n",
    "        temp2 = ls_date.merge(u[['periode', 'Sigma0_VH_db', 'Sigma0_VV_db']], on='periode', how='left')\n",
    "        \n",
    "        # Fill NaN values with 0 in-place\n",
    "        temp2[['Sigma0_VH_db', 'Sigma0_VV_db']] = temp2[['Sigma0_VH_db', 'Sigma0_VV_db']].fillna(0)\n",
    "        \n",
    "        # Add static columns\n",
    "        temp2['idpoint'] = j\n",
    "        temp2['MGRS'] = mgrs_value\n",
    "        \n",
    "        # Compute weight using NumPy for speed\n",
    "        temp2['weight'] = np.where(temp2['Sigma0_VH_db'].values != 0, 1, 0)\n",
    "        \n",
    "        # Only keep the last 30 records and perform the aggregation\n",
    "        temp2 = temp2.iloc[-30:].groupby('idpoint', as_index=False)['weight'].sum()\n",
    "        \n",
    "        # Collect results in a list\n",
    "        temp.append(temp2)\n",
    "\n",
    "# Combine all results at once\n",
    "temp = pd.concat(temp, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204db83-633f-40db-9496-7637df6da277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'periode':list_date})#,colname='periode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd22f2-ee2f-4fd1-95f4-faf0fff4de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pkl='321216004A1#01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4712b-30b2-4660-85cd-42a93a4b9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = dt_pkl.query('idpoint == @idpoint').sort_values('periode')\n",
    "temp=pd.DataFrame()\n",
    "for j in list_date:\n",
    "    item = u.query('periode == @j')\n",
    "    if item.empty:\n",
    "        item = pd.DataFrame({\n",
    "            'idpoint': [idpoint],\n",
    "            'MGRS': [u.MGRS.unique()[0]],\n",
    "            'Sigma0_VH_db': [0],\n",
    "            'Sigma0_VV_db': [0],\n",
    "            'periode': [j]\n",
    "            })\n",
    "    temp = pd.concat([temp, item], ignore_index=True)\n",
    "temp['weight'] = temp['Sigma0_VH_db'].apply(lambda y: 0 if y == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9ca93-4fea-445d-8200-78702153e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.iloc[30:,].groupby('idpoint').agg('sum')[['weight']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa85e66a-4473-4652-9c43-1addcb6d9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.iloc[30:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d853da-46ed-4b37-ba78-3de5c83cc05c",
   "metadata": {},
   "source": [
    "#### temp.iloc[30:,]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
