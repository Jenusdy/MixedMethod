{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf4a789-b354-4205-9d82-a69b3e04bc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:08:48.503702: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-08 11:08:48.506739: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 11:08:48.511345: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 11:08:48.525006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-08 11:08:48.547714: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-08 11:08:48.554081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-08 11:08:48.570521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 11:08:49.874200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5451c2-5599-4094-9512-bd12a542fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/raflizal.fikrar/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.3164 - loss: 23.0523 - val_accuracy: 0.2000 - val_loss: 23.2564\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2034 - loss: 24.0754 - val_accuracy: 0.0000e+00 - val_loss: 25.6316\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0707 - loss: 27.2986 - val_accuracy: 0.0000e+00 - val_loss: 26.0560\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0645 - loss: 27.8010 - val_accuracy: 0.0000e+00 - val_loss: 26.0492\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1180 - loss: 27.8321 - val_accuracy: 0.0000e+00 - val_loss: 26.0162\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0699 - loss: 27.6071 - val_accuracy: 0.0000e+00 - val_loss: 25.9905\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0845 - loss: 27.5725 - val_accuracy: 0.0000e+00 - val_loss: 25.9771\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0773 - loss: 27.4949 - val_accuracy: 0.0000e+00 - val_loss: 25.9757\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1007 - loss: 27.4635 - val_accuracy: 0.0000e+00 - val_loss: 25.9880\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0912 - loss: 27.6749 - val_accuracy: 0.0000e+00 - val_loss: 25.9788\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "Accuracy: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Confusion Matrix:\n",
      " [[  0 199]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/raflizal.fikrar/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/home/raflizal.fikrar/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk menyiapkan data\n",
    "def prepare_data(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(data[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Fungsi untuk membangun model LSTM\n",
    "def build_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Fungsi untuk evaluasi model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, cm\n",
    "\n",
    "# Contoh penggunaan\n",
    "if __name__ == \"__main__\":\n",
    "    # Misalnya Anda memiliki dataframe 'data' dengan fitur dan label\n",
    "    # data = pd.read_csv('your_data.csv')\n",
    "    # X = data['features']\n",
    "    # y = data['labels']\n",
    "\n",
    "    # Contoh data acak untuk tujuan demonstrasi\n",
    "    data = np.random.rand(1000, 10)  # 1000 sampel, 10 fitur\n",
    "    labels = np.random.randint(0, 2, 1000)  # 1000 label biner\n",
    "\n",
    "    # Menyiapkan data\n",
    "    sequence_length = 5\n",
    "    X, y = prepare_data(data, sequence_length)\n",
    "    y = to_categorical(y)  # Konversi label ke format one-hot encoding\n",
    "    \n",
    "    # Membagi data menjadi train dan test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Membangun dan melatih model\n",
    "    model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=y_train.shape[1])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Evaluasi model\n",
    "    accuracy, precision, recall, cm = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Menyimpan model terbaik\n",
    "    with open('best_model.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9432e7a0-a17d-405f-a0f3-a6c1b5ed356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from itertools import compress\n",
    "import geopandas as gpd\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from dtaidistance import dtw\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e429531-1864-4e09-9886-53b9abc807a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (10945, 5, 10)\n",
      "Shape of y: (10945, 10)\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes, title, dataset_name):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    percentages = (cm.T / cm.sum(axis=1) * 100).T\n",
    "    plt.imshow(percentages, interpolation='nearest', cmap=plt.cm.Blues, vmin=0, vmax=100)\n",
    "    plt.title(f'Confusion Matrix - {title} - {dataset_name}')\n",
    "    plt.colorbar(label='Percentage')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            plt.text(j, i, f\"{cm[i, j]}\\n{percentages[i, j]:.1f}%\", horizontalalignment='center',\n",
    "                     color='white' if percentages[i, j] > 50 else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def prepare_data(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(data[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_lstm_model(units=50, dropout_rate=0.2, input_shape=(5, 10), num_classes=2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modeling(Y, X, nama_model, image=False):\n",
    "    # Stratified split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, temp_index in sss.split(X, Y):\n",
    "        X_train, X_temp = X[train_index], X[temp_index]\n",
    "        Y_train, Y_temp = Y[train_index], Y[temp_index]\n",
    "\n",
    "    sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "    for test_index, val_index in sss_val.split(X_temp, Y_temp):\n",
    "        X_test, X_val = X_temp[test_index], X_temp[val_index]\n",
    "        Y_test, Y_val = Y_temp[test_index], Y_temp[val_index]\n",
    "\n",
    "    # One-hot encoding for labels\n",
    "    num_classes = len(np.unique(Y))\n",
    "    Y_train = to_categorical(Y_train, num_classes=num_classes)\n",
    "    Y_test = to_categorical(Y_test, num_classes=num_classes)\n",
    "    Y_val = to_categorical(Y_val, num_classes=num_classes)\n",
    "\n",
    "    # Grid search untuk hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'units': [50, 100],\n",
    "        'dropout_rate': [0.2, 0.3],\n",
    "        'batch_size': [16, 32],\n",
    "        'epochs': [10, 20]\n",
    "    }\n",
    "\n",
    "    def build_model(units, dropout_rate):\n",
    "        return create_lstm_model(units=units, dropout_rate=dropout_rate, input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=num_classes)\n",
    "\n",
    "    model = KerasClassifier(build_fn=build_model, verbose=0)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "    grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "    # Model terbaik\n",
    "    best_model = grid_result.best_estimator_\n",
    "    print(\"Best parameters:\", grid_result.best_params_)\n",
    "\n",
    "    # Evaluasi model\n",
    "    Y_val_pred_prob = best_model.predict_proba(X_val)\n",
    "    Y_val_pred = np.argmax(Y_val_pred_prob, axis=1)\n",
    "    Y_true = np.argmax(Y_val, axis=1)\n",
    "\n",
    "    accuracy_val_pred = accuracy_score(Y_true, Y_val_pred)\n",
    "    precision_val_pred = precision_score(Y_true, Y_val_pred, average='weighted')\n",
    "    recall_val_pred = recall_score(Y_true, Y_val_pred, average='weighted')\n",
    "    cm = confusion_matrix(Y_true, Y_val_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_val_pred)\n",
    "    print(\"Precision:\", precision_val_pred)\n",
    "    print(\"Recall:\", recall_val_pred)\n",
    "    plot_confusion_matrix(cm, classes=np.unique(Y_true), title=nama_model, dataset_name='Validation')\n",
    "\n",
    "    # Save the best model\n",
    "    joblib.dump(best_model, f'best_model_{nama_model}.pkl')\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def model_utilization(data, sequence_length, nama_model):\n",
    "    # Contoh data acak untuk tujuan demonstrasi\n",
    "    labels = np.random.randint(0, 2, len(data))\n",
    "\n",
    "    # Menyiapkan data\n",
    "    X, y = prepare_data(data, sequence_length)\n",
    "\n",
    "    # Check if all classes have at least 2 samples\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    for label, count in zip(unique, counts):\n",
    "        if count < 2:\n",
    "            indices = np.where(y == label)[0]\n",
    "            needed_samples = 2 - count\n",
    "            additional_samples = np.random.choice(indices, needed_samples, replace=True)\n",
    "            X = np.concatenate([X, X[additional_samples]], axis=0)\n",
    "            y = np.concatenate([y, y[additional_samples]], axis=0)\n",
    "\n",
    "    # Cek bentuk data\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "    # Modeling dan evaluasi\n",
    "    best_model = modeling(y, X, nama_model)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Menjalankan fungsi model_utilization jika dijalankan sebagai script utama\n",
    "if __name__ == \"__main__\":\n",
    "    # Contoh data acak untuk tujuan demonstrasi\n",
    "    data = np.random.rand(1000, 10)  # 1000 sampel, 10 fitur\n",
    "    sequence_length = 5\n",
    "\n",
    "    # Nama model untuk disimpan\n",
    "    nama_model = 'LSTM_Model'\n",
    "\n",
    "    # Memanggil fungsi model_utilization\n",
    "    best_model = model_utilization(data, sequence_length, nama_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
